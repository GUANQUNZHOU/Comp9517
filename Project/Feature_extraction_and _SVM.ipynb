{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "from skimage.color import rgb2gray\n",
    "import itertools\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "import tifffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test-train split\n",
    "imageData = os.listdir(\"./data/images\")\n",
    "imageData = [imd for imd in imageData if imd.split('.')[-1] == 'jpg']\n",
    "imageLabel = os.listdir(\"./data/labels\")\n",
    "imageLabel = [iml for iml in imageLabel if iml.split('.')[-1] == 'jpg']\n",
    "#ensure image and labels correspond\n",
    "imageData.sort()\n",
    "imageLabel.sort()\n",
    "trainImage,validImage,trainLable,validLabel = train_test_split(imageData,imageLabel,test_size=0.2,shuffle=True,random_state=2)\n",
    "def addPrefix(x):\n",
    "    pre = x.split(\"-\")[1][0:3]\n",
    "    if(pre == \"vol\"):\n",
    "        return \"./data/images/\" + x\n",
    "    elif(pre == \"lab\"):\n",
    "        return \"./data/labels/\" + x\n",
    "    else:\n",
    "        return \"Invalid input\"\n",
    "tmp = [trainImage,validImage,trainLable,validLabel] \n",
    "\n",
    "trainImage = list(map(addPrefix,trainImage))\n",
    "validImage = list(map(addPrefix,validImage))\n",
    "trainLable = list(map(addPrefix,trainLable))\n",
    "validLabel = list(map(addPrefix,validLabel))\n",
    "\n",
    "finalImage = trainImage+validImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    iv = image\n",
    "    ret,img = cv2.threshold(iv,125,255,cv2.THRESH_BINARY)\n",
    "    _,contours,hierarchy = cv2.findContours(img,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    thres_blob_area = 20\n",
    "    for i in range(len(contours)):\n",
    "        index_level = int(hierarchy[0][i][1])\n",
    "        if index_level<= i:\n",
    "            cnt = contours[i]\n",
    "            area = cv2.contourArea(cnt)\n",
    "            if area <= thres_blob_area:\n",
    "                cv2.drawContours(img,[cnt],-1,255,-1,1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patchDiv(list1,labelPath,patchSize=256):\n",
    "    #loop through image and label\n",
    "\n",
    "    imagePatch = []\n",
    "    labelPatch = []\n",
    "    for i in list1:\n",
    "        if(i[-3:] == \"jpg\"):\n",
    "            imageNumber = i.split(\".jpg\")[0][-2:]\n",
    "            imageLabel = \"/train-labels\" + imageNumber + \".jpg\"\n",
    "            ig = cv2.imread(i,0)\n",
    "            img = preprocess(ig)\n",
    "            label = cv2.imread(labelPath + imageLabel,0)\n",
    "            \n",
    "            cutW = img.shape[0]//patchSize\n",
    "            cutH = img.shape[1]//patchSize\n",
    "            #divide image into patch\n",
    "            for w in range(cutW):\n",
    "                for h in range(cutH):\n",
    "                    imagePatch.append(img[w*patchSize:(w+1)*patchSize, h*patchSize:(h+1)*patchSize])\n",
    "                    labelPatch.append(label[w*patchSize:(w+1)*patchSize, h*patchSize:(h+1)*patchSize])\n",
    "    return imagePatch,labelPatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement image patching \n",
    "imgP,labeP = patchDiv(trainImage,\"./data/labels\",patchSize=256)\n",
    "print(\"number of image patch\",len(imgP))\n",
    "print(\"number of label patch\",len(labeP))\n",
    "print(imgP[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fact(mean,h,n):\n",
    "\n",
    "    return fact_iter(0,0,mean,h,n)\n",
    "\n",
    "def fact_iter(product, count, mean,h,n):\n",
    "\n",
    "    if count >= len(n):\n",
    "\n",
    "        return product\n",
    "\n",
    "    return fact_iter(product+(n[count]-mean)**h, count+1,mean,h,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pick = [[0,0],[0,1],[0,2],[1,0],[1,1],[1,2],[2,0],[2,1],[2,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import cv2\n",
    "def patchGen(img,label,patch_size,npatch):\n",
    "    h,w = img.shape[0:2]\n",
    "    #patch_size should be odd\n",
    "    if(patch_size%2 == 0):\n",
    "        patch_size += 1\n",
    "    #image side cut\n",
    "    cut = patch_size // 2\n",
    "    #randomly select npatch patches\n",
    "    patchMatrx = []\n",
    "    patchLabel = []\n",
    "    for i in range(npatch):\n",
    "        randomHeight = np.random.randint(low = cut,high = h-cut,size = 1)\n",
    "        randomWeight = np.random.randint(low = cut,high = w-cut,size = 1)\n",
    "        labelPixel = label[randomWeight,randomHeight]\n",
    "        rowS = randomWeight-cut\n",
    "        colS = randomHeight-cut\n",
    "        matrxImg = []\n",
    "\n",
    "        for j in range(patch_size):#0,1,2\n",
    "            rowImg = []\n",
    " \n",
    "            for k in range(patch_size):\n",
    "                pixel = img[rowS+k,colS+j]\n",
    "                rowImg.append(pixel)\n",
    "            matrxImg.append(rowImg)\n",
    "       \n",
    "        patchMatrx.append(matrxImg)\n",
    "        patchLabel.append(labelPixel)\n",
    "    return np.array(patchMatrx),np.array(patchLabel)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def T_gener(numpy):\n",
    "    training_para = []\n",
    "    for i in numpy:\n",
    "        T = np.zeros((1,24))\n",
    "        for j in range(len(pick)):\n",
    "            T[0][j] = i[pick[j][0],pick[j][1]]\n",
    "        T[0][9] = np.median(i)\n",
    "        T[0][10] = np.max(i)-np.min(i)\n",
    "        T[0][11] = fact(0,2,T[0][:9])\n",
    "        T[0][12] = fact(T[0][9],2,T[0][:9])/9\n",
    "        T[0][13] = fact(T[0][9],3,T[0][:9])/9\n",
    "        T[0][14] = fact(T[0][9],4,T[0][:9])/9\n",
    "        G = np.gradient(i)[0]\n",
    "        for k in range(len(pick)):\n",
    "            T[0][15+k] = G[pick[k][0],pick[k][1]]\n",
    "        training_para.append(T)\n",
    "    return np.array(training_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, y):\n",
    "    start = time.time()\n",
    "    from sklearn.svm import SVC\n",
    "    print ('[INFO] Training Support Vector Machine model.')\n",
    "    model = SVC(gamma = \"auto\",kernel = 'rbf',C = 1000)\n",
    "    model.fit(X, y)\n",
    "\n",
    "    print ('[INFO] Model training complete.')\n",
    "    print ('[INFO] Training Accuracy: %.2f' %model.score(X, y))\n",
    "    stop = time.time()\n",
    "    d = stop - start\n",
    "    print('Running duration is {}'.format(d))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_generator(list1,list2):\n",
    "    for_train = []\n",
    "    for_test = []\n",
    "    for path in range(len(list1)):\n",
    "        img = list1[path]\n",
    "        ret1,lab1 = cv2.threshold(list2[path],127,255,cv2.THRESH_BINARY)\n",
    "        patch_size = 3\n",
    "        patches,label_patch = patchGen(img,lab1,3,1000)\n",
    "        patchNeed = patches.reshape((patches.shape[0],patches.shape[1],patches.shape[2]))\n",
    "        Train = T_gener(patchNeed)\n",
    "        aft = Train.reshape((Train.shape[0],-1))\n",
    "        aft = preprocessing.maxabs_scale(aft,axis=0, copy=True)\n",
    "        for_train.append(aft)\n",
    "        for_test.append(label_patch)\n",
    "        affor_train = np.array(for_train).reshape((-1,24))\n",
    "        affor_test = np.array(for_test).reshape((-1,1))\n",
    "    return affor_train,affor_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre(X,model):\n",
    "    pred = model.predict(X)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalPatch(testImg,patch_size):\n",
    "    h,w = testImg.shape[0:2]\n",
    "    #patch_size should be odd\n",
    "    if(patch_size%2 == 0):\n",
    "        patch_size += 1\n",
    "    #image side cut\n",
    "    cut = patch_size // 2  \n",
    "    patches = []\n",
    "    for row in range(cut,w-cut):\n",
    "        for col in range(cut,h-cut):\n",
    "            rowS = row-cut\n",
    "            colS = col-cut\n",
    "            matrxImg = []\n",
    "            for j in range(patch_size):#0,1,2\n",
    "                rowImg = []\n",
    "                for k in range(patch_size):\n",
    "                    pixel = testImg[rowS+k,colS+j]\n",
    "                    rowImg.append(pixel)\n",
    "                matrxImg.append(rowImg)\n",
    "            patches.append(matrxImg)\n",
    "    return np.array(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeResult(imageList,originalImageShape=512,patchSize=256):\n",
    "    #index: number of elements in the input list for one image\n",
    "    cut = originalImageShape//patchSize\n",
    "    index = cut * cut\n",
    "    count = 0\n",
    "    i = 0\n",
    "    mergedResult = np.zeros((len(imageList)//index, ) + (originalImageShape,originalImageShape))\n",
    "    while(count + index <= len(imageList)):#(4,8,12...) <= 4\n",
    "        vstacked = []\n",
    "        temp = imageList[count:count + index]#[0:4]\n",
    "        flag = 0\n",
    "        for h in range(cut,index):#(2-4)\n",
    "            for r in range(flag,flag + cut):#(0-2),(2-4)\n",
    "                hstacked = temp[r] if(r == flag) else np.hstack((hstacked,temp[r]))\n",
    "            vstacked = hstacked if (len(vstacked)==0) else np.vstack((vstacked,hstacked))\n",
    "            flag = h      \n",
    "        count += index\n",
    "        mergedResult[i] = vstacked\n",
    "        i += 1 \n",
    "    return mergedResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(list_of_pred):\n",
    "    final_image = []\n",
    "    for pro_c in list_of_pred:\n",
    "        img_blur_G_first = cv2.GaussianBlur(pro_c,(5,5),0)\n",
    "        ret1,th1 = cv2.threshold(img_blur_G_first,160,255,cv2.THRESH_BINARY)\n",
    "        img_blur_G_second = cv2.GaussianBlur(th1,(5,5),0)\n",
    "        ree,tth =  cv2.threshold(img_blur_G_second,160,255,cv2.THRESH_BINARY)\n",
    "        fimg = tth/255\n",
    "        final_image.append(fimg)\n",
    "    return final_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveResult(save_path,npyfile,flag_multi_class = False,num_class = 2):\n",
    "    stacked = []\n",
    "    for i,item in enumerate(npyfile):\n",
    "        img = item[:,:].astype('float32')\n",
    "        img = np.expand_dims(img,axis=0)\n",
    "        if(len(stacked)==0):\n",
    "            stacked = img\n",
    "        else:\n",
    "            stacked = np.vstack((stacked,img))\n",
    "    tifffile.imsave(save_path + '/allPredict.tif', stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TTrain,Tlabel = final_generator(imgP,labeP)\n",
    "Tlabel = Tlabel.ravel()\n",
    "model = train_model(TTrain,Tlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valP,valmP = patchDiv(finalImage,\"./data/labels\",patchSize=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_d = []\n",
    "for lm in valP:\n",
    "    img = lm\n",
    "    ee = evalPatch(img,3)\n",
    "    test_d.append(ee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_v = []\n",
    "for td in test_d:\n",
    "    tee = T_gener(td)\n",
    "    aft = tee.reshape((tee.shape[0],-1))\n",
    "    aft = preprocessing.maxabs_scale(aft,axis=0, copy=True)\n",
    "    test_v.append(aft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creat list of prediction outputs\n",
    "test_pre = []\n",
    "for vv in test_v:\n",
    "    pret =  pre(vv,model)\n",
    "    pret = pret.reshape((254,254))\n",
    "    padimg= np.pad(pret, ((1, 1), (1, 1)), 'constant', constant_values=(0, 0))\n",
    "    test_pre.append(padimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedResult = mergeResult(test_pre,originalImageShape=512,patchSize=256)\n",
    "npyfile = postprocess(mergedResult)\n",
    "saveResult('./',npyfile,flag_multi_class = False,num_class = 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
